{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyN2gfEjRwWxWZf79GKkFepu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manvendra0802/html-portfolio/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBJri8C5rB-j",
        "outputId": "d75b0576-b62a-4e9f-eefd-fe728d99711a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Copy the folder from Google Drive to Colab session storage\n",
        "!cp -r '/content/drive/MyDrive/vlg' '/content/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "2sPZB2HCySde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import MeanAbsoluteError\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, ReLU, Add, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import numpy as np\n",
        "from skimage import io, img_as_float\n",
        "import os\n",
        "import glob\n",
        "from skimage.transform import resize\n",
        "import random\n",
        "\n",
        "# Check if GPU is available\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Function to apply radial crop\n",
        "def radial_crop(image, crop_size):\n",
        "    center = (image.shape[0] // 2, image.shape[1] // 2)\n",
        "    radius = min(center[0], center[1], crop_size // 2)\n",
        "    mask = np.zeros((image.shape[0], image.shape[1]), dtype=bool)\n",
        "    Y, X = np.ogrid[:image.shape[0], :image.shape[1]]\n",
        "    dist_from_center = np.sqrt((X - center[1])**2 + (Y - center[0])**2)\n",
        "    mask[dist_from_center <= radius] = True\n",
        "    cropped_image = np.zeros_like(image)\n",
        "    cropped_image[mask] = image[mask]\n",
        "    return resize(cropped_image, (crop_size, crop_size))\n",
        "\n",
        "# Define a simple Residual Block\n",
        "def residual_block(x, filters, kernel_size=(3, 3)):\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = ReLU()(y)\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    return Add()([x, y])\n",
        "\n",
        "# Define the denoising model\n",
        "def build_denoising_model(input_shape):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, (3, 3), padding='same')(inputs)\n",
        "    x = ReLU()(x)\n",
        "\n",
        "    for _ in range(8):  # Number of residual blocks\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
        "    x = ReLU()(x)\n",
        "    outputs = Conv2D(3, (3, 3), padding='same')(x)\n",
        "    outputs = Add()([inputs, outputs])\n",
        "\n",
        "    return Model(inputs, outputs)\n",
        "\n",
        "# Load and preprocess a single image\n",
        "def preprocess_image(img_path, crop_size):\n",
        "    img = img_as_float(io.imread(img_path))\n",
        "    img = radial_crop(img, crop_size)\n",
        "    return img\n",
        "\n",
        "# Data generator for batch processing with augmentation\n",
        "def data_generator(low_folder, high_folder, crop_size, batch_size=32):\n",
        "    low_image_paths = sorted(glob.glob(os.path.join(low_folder, '*.png')))\n",
        "    high_image_paths = sorted(glob.glob(os.path.join(high_folder, '*.png')))\n",
        "\n",
        "    data_gen_args = dict(horizontal_flip=True,\n",
        "                         vertical_flip=True,\n",
        "                         rotation_range=90)\n",
        "\n",
        "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "\n",
        "    while True:\n",
        "        for i in range(0, len(low_image_paths), batch_size):\n",
        "            low_batch_paths = low_image_paths[i:i + batch_size]\n",
        "            high_batch_paths = high_image_paths[i:i + batch_size]\n",
        "\n",
        "            low_images = np.array([preprocess_image(p, crop_size) for p in low_batch_paths])\n",
        "            high_images = np.array([preprocess_image(p, crop_size) for p in high_batch_paths])\n",
        "\n",
        "            yield low_images, high_images\n",
        "\n",
        "# Custom PSNR metric\n",
        "def psnr(y_true, y_pred):\n",
        "    return tf.image.psnr(y_true, y_pred, max_val=1.0)\n",
        "\n",
        "# Training function with learning rate scheduling\n",
        "def train_model(low_folder, high_folder, crop_size, input_shape, epochs=100, batch_size=16):\n",
        "    model = build_denoising_model(input_shape)\n",
        "    model.compile(optimizer=Adam(1e-4), loss=MeanAbsoluteError(), metrics=[psnr])\n",
        "\n",
        "    steps_per_epoch = len(glob.glob(os.path.join(low_folder, '*.png'))) // batch_size\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    lr_scheduler = tf.keras.callbacks.LearningRateScheduler(lambda epoch: 1e-4 * 0.9 ** (epoch // 10))\n",
        "\n",
        "    # Model checkpointing to save best model\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint('denoising_best_model.h5', monitor='val_psnr', mode='max', save_best_only=True, save_weights_only=True)\n",
        "\n",
        "    # Prepare the dataset\n",
        "    train_ds = tf.data.Dataset.from_generator(\n",
        "        lambda: data_generator(low_folder, high_folder, crop_size, batch_size),\n",
        "        output_types=(tf.float32, tf.float32),\n",
        "        output_shapes=((None, crop_size, crop_size, 3), (None, crop_size, crop_size, 3))\n",
        "    )\n",
        "\n",
        "    # Train the model\n",
        "    model.fit(train_ds,\n",
        "              steps_per_epoch=steps_per_epoch,\n",
        "              epochs=epochs,\n",
        "              callbacks=[lr_scheduler, checkpoint],\n",
        "              validation_data=train_ds,\n",
        "              validation_steps=steps_per_epoch // 10)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Example usage\n",
        "low_folder = '/content/vlg/Train/low'\n",
        "high_folder = '/content/vlg/Train/high'\n",
        "\n",
        "# Check if there are files matching the pattern\n",
        "low_image_paths = glob.glob(os.path.join(low_folder, '*.png'))\n",
        "if len(low_image_paths) == 0:\n",
        "    raise ValueError(\"No PNG files found in the directory:\", low_folder)\n",
        "\n",
        "# Determine input shape (256x256x3)\n",
        "crop_size = 256\n",
        "input_shape = (crop_size, crop_size, 3)\n",
        "\n",
        "model = train_model(low_folder, high_folder, crop_size, input_shape)\n",
        "\n",
        "# Save the trained model\n",
        "model.save('denoising_model.h5')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vknuJ_VV3qUm",
        "outputId": "7d1d1fc1-e8b0-4395-caa6-4aacd03273c3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Epoch 1/100\n",
            "30/30 [==============================] - 74s 2s/step - loss: 0.6019 - psnr: -1.4633 - val_loss: 0.1482 - val_psnr: 13.3600 - lr: 1.0000e-04\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 60s 2s/step - loss: 0.3659 - psnr: 2.7805 - val_loss: 0.1654 - val_psnr: 12.8594 - lr: 1.0000e-04\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.2765 - psnr: 5.2429 - val_loss: 0.1631 - val_psnr: 13.1371 - lr: 1.0000e-04\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.2267 - psnr: 7.0779 - val_loss: 0.1990 - val_psnr: 12.6410 - lr: 1.0000e-04\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.1805 - psnr: 8.8768 - val_loss: 0.2101 - val_psnr: 12.4716 - lr: 1.0000e-04\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.1622 - psnr: 10.1726 - val_loss: 0.2082 - val_psnr: 12.5614 - lr: 1.0000e-04\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.1504 - psnr: 10.9539 - val_loss: 0.2140 - val_psnr: 11.9116 - lr: 1.0000e-04\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.1787 - psnr: 11.1045 - val_loss: 0.1632 - val_psnr: 13.5654 - lr: 1.0000e-04\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.1466 - psnr: 12.0002 - val_loss: 0.2277 - val_psnr: 12.2881 - lr: 1.0000e-04\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.1381 - psnr: 12.7042 - val_loss: 0.1795 - val_psnr: 13.8125 - lr: 1.0000e-04\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.1064 - psnr: 13.8200 - val_loss: 0.1774 - val_psnr: 14.1515 - lr: 9.0000e-05\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.1082 - psnr: 14.2978 - val_loss: 0.1846 - val_psnr: 13.3535 - lr: 9.0000e-05\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0913 - psnr: 14.9333 - val_loss: 0.2031 - val_psnr: 13.0204 - lr: 9.0000e-05\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0882 - psnr: 15.4235 - val_loss: 0.2034 - val_psnr: 13.1723 - lr: 9.0000e-05\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.1004 - psnr: 15.3995 - val_loss: 0.2504 - val_psnr: 11.0305 - lr: 9.0000e-05\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0986 - psnr: 15.7180 - val_loss: 0.1800 - val_psnr: 13.6125 - lr: 9.0000e-05\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.1081 - psnr: 15.5162 - val_loss: 0.2353 - val_psnr: 11.3289 - lr: 9.0000e-05\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.1078 - psnr: 15.5145 - val_loss: 0.2312 - val_psnr: 12.0840 - lr: 9.0000e-05\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0942 - psnr: 16.2856 - val_loss: 0.1628 - val_psnr: 14.4615 - lr: 9.0000e-05\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0927 - psnr: 16.7640 - val_loss: 0.1274 - val_psnr: 15.7237 - lr: 9.0000e-05\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0820 - psnr: 17.1524 - val_loss: 0.1222 - val_psnr: 16.9973 - lr: 8.1000e-05\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 50s 2s/step - loss: 0.0807 - psnr: 17.4681 - val_loss: 0.0907 - val_psnr: 18.2185 - lr: 8.1000e-05\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0743 - psnr: 17.8077 - val_loss: 0.0947 - val_psnr: 18.3284 - lr: 8.1000e-05\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0677 - psnr: 18.0154 - val_loss: 0.0782 - val_psnr: 19.1892 - lr: 8.1000e-05\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0699 - psnr: 18.1036 - val_loss: 0.0990 - val_psnr: 17.9640 - lr: 8.1000e-05\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0727 - psnr: 18.1289 - val_loss: 0.0670 - val_psnr: 19.2784 - lr: 8.1000e-05\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0678 - psnr: 18.4418 - val_loss: 0.0753 - val_psnr: 18.9510 - lr: 8.1000e-05\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0623 - psnr: 18.8543 - val_loss: 0.0923 - val_psnr: 18.4710 - lr: 8.1000e-05\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0655 - psnr: 18.6707 - val_loss: 0.1128 - val_psnr: 16.7795 - lr: 8.1000e-05\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0783 - psnr: 18.0694 - val_loss: 0.1115 - val_psnr: 16.9031 - lr: 8.1000e-05\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0656 - psnr: 18.6310 - val_loss: 0.0834 - val_psnr: 18.3436 - lr: 7.2900e-05\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0617 - psnr: 18.9310 - val_loss: 0.0604 - val_psnr: 19.3149 - lr: 7.2900e-05\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0634 - psnr: 19.0815 - val_loss: 0.0786 - val_psnr: 18.5164 - lr: 7.2900e-05\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0782 - psnr: 18.3607 - val_loss: 0.0764 - val_psnr: 18.8170 - lr: 7.2900e-05\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0572 - psnr: 19.5302 - val_loss: 0.0577 - val_psnr: 20.1833 - lr: 7.2900e-05\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0593 - psnr: 19.3878 - val_loss: 0.0505 - val_psnr: 20.8396 - lr: 7.2900e-05\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0638 - psnr: 19.4609 - val_loss: 0.0567 - val_psnr: 20.7221 - lr: 7.2900e-05\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0620 - psnr: 19.4605 - val_loss: 0.0748 - val_psnr: 20.1590 - lr: 7.2900e-05\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0592 - psnr: 19.8004 - val_loss: 0.0600 - val_psnr: 20.9420 - lr: 7.2900e-05\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0509 - psnr: 20.2265 - val_loss: 0.0595 - val_psnr: 21.1154 - lr: 7.2900e-05\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0592 - psnr: 19.9229 - val_loss: 0.0573 - val_psnr: 20.9788 - lr: 6.5610e-05\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0583 - psnr: 20.1941 - val_loss: 0.0766 - val_psnr: 19.7325 - lr: 6.5610e-05\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0590 - psnr: 20.1243 - val_loss: 0.0624 - val_psnr: 20.4798 - lr: 6.5610e-05\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0531 - psnr: 20.4457 - val_loss: 0.0680 - val_psnr: 20.2621 - lr: 6.5610e-05\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0502 - psnr: 20.5724 - val_loss: 0.0521 - val_psnr: 21.3489 - lr: 6.5610e-05\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0489 - psnr: 20.8265 - val_loss: 0.0556 - val_psnr: 20.9435 - lr: 6.5610e-05\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0463 - psnr: 21.0256 - val_loss: 0.0536 - val_psnr: 20.9951 - lr: 6.5610e-05\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0513 - psnr: 20.9828 - val_loss: 0.0507 - val_psnr: 20.8410 - lr: 6.5610e-05\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0583 - psnr: 20.4739 - val_loss: 0.0792 - val_psnr: 19.6036 - lr: 6.5610e-05\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0593 - psnr: 20.4763 - val_loss: 0.0531 - val_psnr: 21.3106 - lr: 6.5610e-05\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0493 - psnr: 21.1198 - val_loss: 0.0471 - val_psnr: 21.4576 - lr: 5.9049e-05\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0467 - psnr: 21.3795 - val_loss: 0.0540 - val_psnr: 21.3655 - lr: 5.9049e-05\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0469 - psnr: 21.4292 - val_loss: 0.0572 - val_psnr: 20.8826 - lr: 5.9049e-05\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0477 - psnr: 21.4492 - val_loss: 0.0517 - val_psnr: 21.4202 - lr: 5.9049e-05\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0538 - psnr: 20.9988 - val_loss: 0.0525 - val_psnr: 21.3813 - lr: 5.9049e-05\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0488 - psnr: 21.3191 - val_loss: 0.0548 - val_psnr: 21.2159 - lr: 5.9049e-05\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0567 - psnr: 20.9700 - val_loss: 0.0546 - val_psnr: 21.1225 - lr: 5.9049e-05\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0530 - psnr: 21.2174 - val_loss: 0.0590 - val_psnr: 20.6903 - lr: 5.9049e-05\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0449 - psnr: 21.6572 - val_loss: 0.0435 - val_psnr: 21.5154 - lr: 5.9049e-05\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0485 - psnr: 21.4776 - val_loss: 0.0540 - val_psnr: 20.7082 - lr: 5.9049e-05\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0492 - psnr: 21.5207 - val_loss: 0.0566 - val_psnr: 21.1085 - lr: 5.3144e-05\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0468 - psnr: 21.7053 - val_loss: 0.0525 - val_psnr: 21.0097 - lr: 5.3144e-05\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 58s 2s/step - loss: 0.0464 - psnr: 21.7129 - val_loss: 0.0497 - val_psnr: 21.4248 - lr: 5.3144e-05\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0461 - psnr: 21.8632 - val_loss: 0.0533 - val_psnr: 21.5462 - lr: 5.3144e-05\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0452 - psnr: 21.8662 - val_loss: 0.0404 - val_psnr: 22.3396 - lr: 5.3144e-05\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0438 - psnr: 21.8851 - val_loss: 0.0558 - val_psnr: 21.8557 - lr: 5.3144e-05\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 57s 2s/step - loss: 0.0419 - psnr: 22.0455 - val_loss: 0.0452 - val_psnr: 22.6818 - lr: 5.3144e-05\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0403 - psnr: 22.2725 - val_loss: 0.0464 - val_psnr: 22.7172 - lr: 5.3144e-05\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0413 - psnr: 22.1281 - val_loss: 0.0463 - val_psnr: 22.8013 - lr: 5.3144e-05\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0438 - psnr: 22.0509 - val_loss: 0.0551 - val_psnr: 22.3704 - lr: 5.3144e-05\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 55s 2s/step - loss: 0.0460 - psnr: 22.0804 - val_loss: 0.0492 - val_psnr: 22.3261 - lr: 4.7830e-05\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0393 - psnr: 22.2567 - val_loss: 0.0433 - val_psnr: 22.7405 - lr: 4.7830e-05\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0416 - psnr: 22.3405 - val_loss: 0.0504 - val_psnr: 22.2310 - lr: 4.7830e-05\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0433 - psnr: 22.1987 - val_loss: 0.0622 - val_psnr: 21.5729 - lr: 4.7830e-05\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0492 - psnr: 22.0051 - val_loss: 0.0497 - val_psnr: 22.0349 - lr: 4.7830e-05\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0419 - psnr: 22.3619 - val_loss: 0.0392 - val_psnr: 22.3945 - lr: 4.7830e-05\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0425 - psnr: 22.3812 - val_loss: 0.0588 - val_psnr: 21.4678 - lr: 4.7830e-05\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 50s 2s/step - loss: 0.0403 - psnr: 22.5754 - val_loss: 0.0401 - val_psnr: 22.3284 - lr: 4.7830e-05\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 56s 2s/step - loss: 0.0423 - psnr: 22.5435 - val_loss: 0.0551 - val_psnr: 21.4439 - lr: 4.7830e-05\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 50s 2s/step - loss: 0.0405 - psnr: 22.4628 - val_loss: 0.0389 - val_psnr: 21.9182 - lr: 4.7830e-05\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0387 - psnr: 22.5616 - val_loss: 0.0422 - val_psnr: 22.3446 - lr: 4.3047e-05\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0398 - psnr: 22.7461 - val_loss: 0.0475 - val_psnr: 22.0620 - lr: 4.3047e-05\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0380 - psnr: 22.7940 - val_loss: 0.0524 - val_psnr: 22.2180 - lr: 4.3047e-05\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0382 - psnr: 22.8538 - val_loss: 0.0450 - val_psnr: 22.4008 - lr: 4.3047e-05\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0433 - psnr: 22.5653 - val_loss: 0.0452 - val_psnr: 22.6040 - lr: 4.3047e-05\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 63s 2s/step - loss: 0.0375 - psnr: 22.7917 - val_loss: 0.0368 - val_psnr: 22.7613 - lr: 4.3047e-05\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 48s 2s/step - loss: 0.0358 - psnr: 22.8893 - val_loss: 0.0367 - val_psnr: 22.8247 - lr: 4.3047e-05\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0398 - psnr: 22.8140 - val_loss: 0.0376 - val_psnr: 22.6430 - lr: 4.3047e-05\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 49s 2s/step - loss: 0.0359 - psnr: 22.9728 - val_loss: 0.0480 - val_psnr: 22.2892 - lr: 4.3047e-05\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 54s 2s/step - loss: 0.0361 - psnr: 22.9781 - val_loss: 0.0442 - val_psnr: 22.1913 - lr: 4.3047e-05\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0350 - psnr: 23.0321 - val_loss: 0.0357 - val_psnr: 22.4996 - lr: 3.8742e-05\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 49s 2s/step - loss: 0.0365 - psnr: 23.0827 - val_loss: 0.0369 - val_psnr: 22.3495 - lr: 3.8742e-05\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0367 - psnr: 23.1306 - val_loss: 0.0457 - val_psnr: 22.4034 - lr: 3.8742e-05\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0376 - psnr: 23.1007 - val_loss: 0.0422 - val_psnr: 22.4414 - lr: 3.8742e-05\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0377 - psnr: 23.0969 - val_loss: 0.0379 - val_psnr: 22.8886 - lr: 3.8742e-05\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 50s 2s/step - loss: 0.0361 - psnr: 23.1765 - val_loss: 0.0359 - val_psnr: 23.3631 - lr: 3.8742e-05\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0347 - psnr: 23.1965 - val_loss: 0.0349 - val_psnr: 23.6759 - lr: 3.8742e-05\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 53s 2s/step - loss: 0.0357 - psnr: 23.2181 - val_loss: 0.0400 - val_psnr: 23.2036 - lr: 3.8742e-05\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 51s 2s/step - loss: 0.0361 - psnr: 23.2957 - val_loss: 0.0400 - val_psnr: 23.3979 - lr: 3.8742e-05\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 52s 2s/step - loss: 0.0378 - psnr: 23.1207 - val_loss: 0.0457 - val_psnr: 23.2524 - lr: 3.8742e-05\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}